{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed75e66-dbb9-47cc-bb0f-a8160a197ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "# add to the path the source files\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from dgl.data.utils import load_graphs\n",
    "import dgl\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch_geometric \n",
    "from torch_geometric.loader import DataLoader\n",
    "import networkx as nx\n",
    "from src.dataset.counting_algorithm import subgraph_counting\n",
    "#from src.baseline.model_gcn import GCN, GIN\n",
    "from src.baseline.dataset_gcn import GraphDataset\n",
    "from src.metrics.L1_based import L1LossCount, L1LossStd\n",
    "from matplotlib import pyplot as plt\n",
    "from src.baseline.model_gcn import GCN, GIN\n",
    "from src.I2GNN.I2GNN import I2GNN\n",
    "from src.ppgn.ppgn import PPGN, PPGNexpl\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_gnn_input(graph: nx.Graph, device)->torch_geometric.data.Data:\n",
    "    \"\"\"Creates from a networkx graph a Data instance, which is the input a a pytorch geometric model.\"\"\"\n",
    "    x = torch.ones(graph.number_of_nodes(), 1) # no improovement by using more channels in the first layer\n",
    "    num_edges = graph.number_of_edges()\n",
    "    edge_index = torch.empty(2, 2*num_edges, dtype=torch.long)\n",
    "    for i, edge in enumerate(graph.edges()):\n",
    "        edge_index[0,i] = edge[0]\n",
    "        edge_index[1,i] = edge[1]\n",
    "        edge_index[0, i+num_edges] = edge[1]\n",
    "        edge_index[1, i+num_edges] = edge[0]\n",
    "    return torch_geometric.data.Data(x=x, edge_index=edge_index).to(device)\n",
    "\n",
    "loss_fn = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb63a578-1116-49dc-9954-7bc50851947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/campi/robustness-of-subgraphs-count/tests/processed\n",
      "229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/campi/robustness-of-subgraphs-count/tests/processed\n",
      "224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/campi/robustness-of-subgraphs-count/tests/processed\n",
      "218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/campi/robustness-of-subgraphs-count/tests/processed\n",
      "[0.0067195892333984375, 0.009820938110351562, 0.011531829833984375, 0.01264190673828125], time: 31.46625304222107\n",
      "/nfs/homedirs/campi/robustness-of-subgraphs-count/tests/processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/campi/robustness-of-subgraphs-count/tests/processed\n",
      "224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/campi/robustness-of-subgraphs-count/tests/processed\n",
      "218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/campi/robustness-of-subgraphs-count/tests/processed\n",
      "[0.0067195892333984375, 0.009820938110351562, 0.011531829833984375, 0.01264190673828125], time: 31.375270128250122\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'root'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1238496/163742922.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{adversarial_error_history}, time: {time.time() - start}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'root'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'root'"
     ]
    }
   ],
   "source": [
    "# robustness greedy\n",
    "# from src.adversarial.beam_attack import PreserveBeamAttack, SubstructurePreserveBeamAttack, BeamAttack\n",
    "from src.adversarial.beam_attack_I2GNN import I2GNNPreserveBeamAttack, I2GNNSubstructurePreserveBeamAttack, I2GNNBeamAttack\n",
    "from src.adversarial.beam_attack import PreserveBeamAttack, SubstructurePreserveBeamAttack, BeamAttack\n",
    "from src.adversarial.greedy_attack import PreserveGreedyAttack\n",
    "from src.dataset.counting_algorithm import subgraph_counting, subgraph_listing\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import shutil\n",
    "\n",
    "task = 'Triangle'\n",
    "device = 'cpu'\n",
    "dataset = 'sbm_30'\n",
    "model = 'I2GNN'\n",
    "dataset_path = f\"/nfs/students/campi/dataset/training/test_5000_{dataset}.bin\"\n",
    "models_path = [f\"//nfs/students/campi/best_models/{model}_{dataset}/{model}_{task}_{i}.pth\" for i in range(5)]\n",
    "dict_path = [f\"//nfs/students/campi/best_models/{model}_{dataset}/{model}_{task}_{i}.json\" for i in range(5)]\n",
    "i = 0\n",
    "with open(dict_path[0], 'r') as f:\n",
    "    h_params = json.load(f)\n",
    "if model == 'PPGN':\n",
    "    gnn = PPGN(**h_params)\n",
    "if model == 'I2GNN':\n",
    "    gnn = I2GNN(**h_params)\n",
    "gnn.load_state_dict(torch.load(models_path[0], map_location=torch.device(device)))\n",
    "gnn.eval()\n",
    "\n",
    "graphs, counts = dgl.load_graphs(dataset_path)\n",
    "graph = nx.Graph(dgl.to_networkx(graphs[i]))\n",
    "count = counts[task][i]\n",
    "\n",
    "start = time.time()\n",
    "if model == 'PPGN':\n",
    "    greedy_attack = SubstructurePreserveBeamAttack(n_samples = 1, edge_addition=True, edge_deletion=True, device=device)\n",
    "if model =='I2GNN':\n",
    "    greedy_attack = I2GNNSubstructurePreserveBeamAttack(n_samples = 1, edge_addition=True, edge_deletion=True, device=device)\n",
    "adversarial_graph, adversarial_error_history, adversarial_count = greedy_attack.find_adversarial_example(budget=3, gnn=gnn, loss_fn=loss_fn, graph=graph,subgraph_type=task,count=count)\n",
    "print(f'{adversarial_error_history}, time: {time.time() - start}')\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "if model == 'PPGN':\n",
    "    greedy_attack2 = PreserveBeamAttack(n_samples = 1, edge_addition=True, edge_deletion=True, device=device)\n",
    "if model =='I2GNN':\n",
    "    greedy_attack2 = I2GNNPreserveBeamAttack(n_samples = 1, edge_addition=True, edge_deletion=True, device=device)\n",
    "adversarial_graph, adversarial_error_history, adversarial_count = greedy_attack2.find_adversarial_example(budget=3, gnn=gnn, loss_fn=loss_fn, graph=graph,subgraph_type=task,count=count)\n",
    "print(f'{adversarial_error_history}, time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e9ce9-a835-4c02-a303-d0184d975df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# robustness greedy\n",
    "from src.adversarial.max_similar import MaximizeSimilar\n",
    "from src.dataset.counting_algorithm import subgraph_counting, subgraph_listing\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "task = 'Chordal cycle'\n",
    "similar_task = 'Tailed triangle'\n",
    "device = 'cpu'\n",
    "dataset = 'er_10'\n",
    "dataset_path = f\"/nfs/students/campi/dataset/training/test_5000_{dataset}.bin\"\n",
    "models_path = [f\"//nfs/students/campi/best_models/PPGN_{dataset}/PPGN_{task}_{i}.pth\" for i in range(5)]\n",
    "dict_path = [f\"//nfs/students/campi/best_models/PPGN_{dataset}/PPGN_{task}_{i}.json\" for i in range(5)]\n",
    "i = 30\n",
    "with open(dict_path[0], 'r') as f:\n",
    "    h_params = json.load(f)\n",
    "gnn = PPGN(**h_params)\n",
    "gnn.load_state_dict(torch.load(models_path[0], map_location=torch.device(device)))\n",
    "gnn.eval()\n",
    "\n",
    "graphs, counts = dgl.load_graphs(dataset_path)\n",
    "graph = nx.Graph(dgl.to_networkx(graphs[i]))\n",
    "count = counts[task][i]\n",
    "similar_count = counts[similar_task][i]\n",
    "\n",
    "#maximize the count of tailed triangles\n",
    "budget = 60\n",
    "increase = True\n",
    "preserve = False\n",
    "attack = MaximizeSimilar(preserve=preserve)\n",
    "adv_example, similar_adv_count = attack.find_adversarial_example(budget, graph, task, count, similar_task, increase)\n",
    "print(f'Initial: {similar_count}, final {similar_adv_count}')\n",
    "\n",
    "print(f'Test prediction: {gnn(generate_gnn_input(graph, device))}, gt: {count}, num edges: {graph.number_of_edges()}')\n",
    "print(f'Adv prediction: {gnn(generate_gnn_input(adv_example, device))}, gt: {count}, num_edges: {adv_example.number_of_edges()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f643b07-56f3-4aae-b7a4-bc4da8b441b6",
   "metadata": {},
   "source": [
    "saliency map with gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162be56-d2dd-4b86-b2d2-59abcad08e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.counting_algorithm import subgraph_counting, subgraph_listing\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "task ='Chordal cycle'\n",
    "similar_task = '4-Clique'\n",
    "device = 'cpu'\n",
    "dataset = 'er_10'\n",
    "dataset_path = f\"/nfs/students/campi/dataset/training/test_5000_{dataset}.bin\"\n",
    "models_path = [f\"//nfs/students/campi/best_models/PPGN_{dataset}/PPGN_{task}_{i}.pth\" for i in range(5)]\n",
    "dict_path = [f\"//nfs/students/campi/best_models/PPGN_{dataset}/PPGN_{task}_{i}.json\" for i in range(5)]\n",
    "i = 1\n",
    "with open(dict_path[0], 'r') as f:\n",
    "    h_params = json.load(f)\n",
    "gnn = PPGNexpl(**h_params)\n",
    "gnn.load_state_dict(torch.load(models_path[0], map_location=torch.device(device)))\n",
    "\n",
    "graphs, counts = dgl.load_graphs(dataset_path)\n",
    "graph = nx.Graph(dgl.to_networkx(graphs[i]))\n",
    "nx.draw(graph,with_labels=True)\n",
    "plt.show()\n",
    "count = counts[task][i]\n",
    "subgraphs = subgraph_listing(graph, task)\n",
    "subhraphs_similar = subgraph_listing(graph, similar_task)\n",
    "edge_count = torch.zeros((graph.number_of_nodes(), graph.number_of_nodes()))\n",
    "similar_edge_count = torch.zeros((graph.number_of_nodes(), graph.number_of_nodes()))\n",
    "sub_edges = []\n",
    "for sub in subgraphs:\n",
    "    for edge in graph.subgraph(sub).edges():\n",
    "        edge_count[edge[0], edge[1]] += 1\n",
    "        edge_count[edge[1], edge[0]] += 1\n",
    "        sub_edges.append(edge)\n",
    "for sub in subhraphs_similar:\n",
    "    for edge in graph.subgraph(sub).edges():\n",
    "        similar_edge_count[edge[0], edge[1]] += 1\n",
    "        similar_edge_count[edge[1], edge[0]] += 1\n",
    "print(edge_count)\n",
    "print(similar_edge_count)\n",
    "\n",
    "data = generate_gnn_input(graph, device)\n",
    "pred = gnn(data)\n",
    "pred.backward()\n",
    "grad = torch.squeeze(gnn.adj.grad)\n",
    "grad = ((grad + grad.T)*gnn.adj)\n",
    "print(grad)\n",
    "grad_f = grad.flatten()\n",
    "print(grad_f[torch.nonzero(grad_f).flatten()])\n",
    "for i in range(graph.number_of_nodes()):\n",
    "    for j in range(i+1, graph.number_of_nodes()):\n",
    "        print(f'edge({i},{j}): {grad[i,j]}')\n",
    "#print(grad)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70acb805-0e35-4cbd-aea2-73c5a5ef20df",
   "metadata": {},
   "source": [
    "saliency map with masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23395ef-5c09-46d1-8826-434da8633e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.counting_algorithm import subgraph_counting, subgraph_listing\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "\n",
    "task ='Chordal cycle'\n",
    "similar_task = '4-Clique'\n",
    "device = 'cpu'\n",
    "dataset = 'er_10'\n",
    "dataset_path = f\"/nfs/students/campi/dataset/training/test_5000_{dataset}.bin\"\n",
    "models_path = [f\"//nfs/students/campi/best_models/PPGN_{dataset}/PPGN_{task}_{i}.pth\" for i in range(5)]\n",
    "dict_path = [f\"//nfs/students/campi/best_models/PPGN_{dataset}/PPGN_{task}_{i}.json\" for i in range(5)]\n",
    "i = 1\n",
    "with open(dict_path[0], 'r') as f:\n",
    "    h_params = json.load(f)\n",
    "gnn = PPGNexpl(**h_params)\n",
    "gnn.load_state_dict(torch.load(models_path[0], map_location=torch.device(device)))\n",
    "\n",
    "graphs, counts = dgl.load_graphs(dataset_path)\n",
    "graph = nx.Graph(dgl.to_networkx(graphs[i]))\n",
    "nx.draw(graph,with_labels=True)\n",
    "plt.show()\n",
    "count = counts[task][i]\n",
    "subgraphs = subgraph_listing(graph, task)\n",
    "\n",
    "data = generate_gnn_input(graph, device)\n",
    "pred = gnn(data)\n",
    "sal = torch.zeros((graph.number_of_nodes(), graph.number_of_nodes()))\n",
    "for e in graph.edges():\n",
    "    new_graph = copy.deepcopy(graph)\n",
    "    new_graph.remove_edge(*e)\n",
    "    data = generate_gnn_input(new_graph, device)\n",
    "    new_pred = gnn(data)\n",
    "    sal[e[0], e[1]] = new_pred - pred\n",
    "    sal[e[1], e[0]] = new_pred - pred\n",
    "\n",
    "for e in nx.non_edges(graph):\n",
    "    new_graph = copy.deepcopy(graph)\n",
    "    new_graph.add_edge(*e)\n",
    "    data = generate_gnn_input(new_graph, device)\n",
    "    new_pred = gnn(data)\n",
    "    sal[e[0], e[1]] = new_pred - pred\n",
    "    sal[e[1], e[0]] = new_pred - pred\n",
    "    \n",
    "subhraphs_similar = subgraph_listing(graph, similar_task)\n",
    "edge_count = torch.zeros((graph.number_of_nodes(), graph.number_of_nodes()))\n",
    "similar_edge_count = torch.zeros((graph.number_of_nodes(), graph.number_of_nodes()))\n",
    "sub_edges = []\n",
    "for sub in subgraphs:\n",
    "    for edge in graph.subgraph(sub).edges():\n",
    "        edge_count[edge[0], edge[1]] += 1\n",
    "        edge_count[edge[1], edge[0]] += 1\n",
    "        sub_edges.append(edge)\n",
    "        \n",
    "for sub in subhraphs_similar:\n",
    "    for edge in graph.subgraph(sub).edges():\n",
    "        similar_edge_count[edge[0], edge[1]] += 1\n",
    "        similar_edge_count[edge[1], edge[0]] += 1\n",
    "print(edge_count)\n",
    "print(similar_edge_count)\n",
    "\n",
    "for i in range(graph.number_of_nodes()):\n",
    "    for j in range(i+1, graph.number_of_nodes()):\n",
    "        print(f'edge({i},{j}): {sal[i,j]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07da2ab-82e8-4aa1-98c9-8a0d1f000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = GraphDataset(dataset_path=dataset_path, task=task, in_channels=1)\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "preds = []\n",
    "gt = []\n",
    "start = time.time()\n",
    "with torch.no_grad():\n",
    "    for data, y in dataloader:\n",
    "        data = data.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = gnn(data)\n",
    "        preds.extend(pred.flatten().tolist())\n",
    "        gt.extend(y.flatten().tolist())\n",
    "print(f'time: {time.time() - start}')\n",
    "plt.hist(preds, bins=20)\n",
    "plt.title(\"Predictions distribution\")\n",
    "plt.show()\n",
    "plt.hist(gt, bins=20)\n",
    "plt.title(\"Ground truth distribution\")\n",
    "plt.show()\n",
    "plt.scatter(gt, preds)\n",
    "plt.title(\"Models predictions vs groud truths\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7975ca5-30d1-4c31-a720-7edec5b680ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d2f52-ecfd-4840-ad5c-491f1c453c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
