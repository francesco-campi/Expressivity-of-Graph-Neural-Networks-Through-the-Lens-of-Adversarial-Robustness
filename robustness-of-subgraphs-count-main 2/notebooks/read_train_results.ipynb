{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the results of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seml\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from torch_geometric.loader import DataLoader\n",
    "from statistics import mean, median\n",
    "from tqdm import tqdm\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import torch_geometric\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from src.baseline.model_gcn import GIN\n",
    "from src.ppgn.ppgn import PPGN\n",
    "from src.I2GNN.I2GNN import I2GNN\n",
    "from src.baseline.dataset_gcn import GraphDataset\n",
    "from src.I2GNN.I2GNN_dataset import I2GNNDataset, I2GNNDataLoader, I2GNNDatasetRobustness\n",
    "from src.metrics.L1_based import L1LossCount, L1LossStd\n",
    "from src.I2GNN.utils import create_subgraphs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 'dataset_2'\n",
    "exp = 'er_10'\n",
    "arch = \"I2GNN\"\n",
    "device = 'cuda'\n",
    "experiment_name = f'train_{arch}_{exp}'\n",
    "results: pd.DataFrame = seml.get_results(experiment_name, to_data_frame=True)\n",
    "results.index = results[\"_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "substrucutres = results['config.subgraph'].unique()\n",
    "best_l1 = pd.DataFrame(columns=[\"Best_model\", \"L1\", \"L1 std\", \"L1 count\", \"Mean\", \"Varience\", \"Std\"], index=substrucutres)\n",
    "# best_l1_std = pd.DataFrame(columns=[\"Best_model\", \"L1 std\", \"Mean\", \"Varience\", \"Std\"], index=substrucutres)\n",
    "# best_l1_count = pd.DataFrame(columns=[\"Best_model\", \"L1 count\", \"Mean\", \"Varience\", \"Std\"], index=substrucutres)\n",
    "for substrcuture in substrucutres:\n",
    "    substructure_experiments = results[results['config.subgraph'] == substrcuture]\n",
    "    best_experiment_l1 = substructure_experiments.sort_values(axis=0, by='result.l1_average').head(1).squeeze()\n",
    "    # best_experiment_l1_std = substructure_experiments.sort_values(axis=0, by='result.l1').head(1).squeeze()\n",
    "    # best_experiment_l1_count = substructure_experiments.sort_values(axis=0, by='result.l1').head(1).squeeze()\n",
    "    \n",
    "    best_l1.loc[substrcuture] = [best_experiment_l1['_id'], best_experiment_l1['result.l1_average'], best_experiment_l1['result.l1_std_average'], \n",
    "    best_experiment_l1['result.l1_count_average'], best_experiment_l1['result.count_mean'], best_experiment_l1['result.count_variance'], best_experiment_l1['result.count_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models with l1 loss:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best_model</th>\n",
       "      <th>L1</th>\n",
       "      <th>L1 std</th>\n",
       "      <th>L1 count</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Varience</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Triangle</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00223</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>7.632</td>\n",
       "      <td>21.449957</td>\n",
       "      <td>4.63141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-Path</th>\n",
       "      <td>2</td>\n",
       "      <td>0.027203</td>\n",
       "      <td>0.00296</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>34.616001</td>\n",
       "      <td>84.432716</td>\n",
       "      <td>9.188727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-Clique</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.824</td>\n",
       "      <td>2.212309</td>\n",
       "      <td>1.487383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chordal cycle</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>7.6836</td>\n",
       "      <td>50.046711</td>\n",
       "      <td>7.07437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailed triangle</th>\n",
       "      <td>5</td>\n",
       "      <td>0.061716</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>23.134399</td>\n",
       "      <td>146.820663</td>\n",
       "      <td>12.116958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-Star</th>\n",
       "      <td>6</td>\n",
       "      <td>0.079077</td>\n",
       "      <td>0.013998</td>\n",
       "      <td>0.007414</td>\n",
       "      <td>11.692</td>\n",
       "      <td>31.911501</td>\n",
       "      <td>5.649026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-Cycle</th>\n",
       "      <td>7</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.00607</td>\n",
       "      <td>5.8216</td>\n",
       "      <td>19.283087</td>\n",
       "      <td>4.391251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-Path</th>\n",
       "      <td>8</td>\n",
       "      <td>0.062456</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>34.9716</td>\n",
       "      <td>108.471779</td>\n",
       "      <td>10.414979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-Star not ind.</th>\n",
       "      <td>9</td>\n",
       "      <td>0.035508</td>\n",
       "      <td>0.00113</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>53.489601</td>\n",
       "      <td>986.939087</td>\n",
       "      <td>31.415586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Best_model        L1    L1 std  L1 count       Mean  \\\n",
       "Triangle                 1   0.00223  0.000482  0.000261      7.632   \n",
       "2-Path                   2  0.027203   0.00296  0.000786  34.616001   \n",
       "4-Clique                 3  0.001608  0.001081  0.000327      0.824   \n",
       "Chordal cycle            4   0.01966  0.002779  0.002505     7.6836   \n",
       "Tailed triangle          5  0.061716  0.005093  0.002864  23.134399   \n",
       "3-Star                   6  0.079077  0.013998  0.007414     11.692   \n",
       "4-Cycle                  7  0.035215  0.008019   0.00607     5.8216   \n",
       "3-Path                   8  0.062456  0.005997  0.002069    34.9716   \n",
       "3-Star not ind.          9  0.035508   0.00113  0.000864  53.489601   \n",
       "\n",
       "                   Varience        Std  \n",
       "Triangle          21.449957    4.63141  \n",
       "2-Path            84.432716   9.188727  \n",
       "4-Clique           2.212309   1.487383  \n",
       "Chordal cycle     50.046711    7.07437  \n",
       "Tailed triangle  146.820663  12.116958  \n",
       "3-Star            31.911501   5.649026  \n",
       "4-Cycle           19.283087   4.391251  \n",
       "3-Path           108.471779  10.414979  \n",
       "3-Star not ind.  986.939087  31.415586  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Best models with l1 loss:\")\n",
    "display(best_l1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the best models we can test them on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(dataloader, gnn, loss_fn, device)->torch.Tensor:\n",
    "    gnn.eval()\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(dataloader)\n",
    "        loss = torch.zeros(len(l)).to(device)\n",
    "        for data in dataloader:\n",
    "            data = data.to(device)\n",
    "            y = data.y\n",
    "            pred = gnn(data)\n",
    "            for i, loss_fn in enumerate(l):\n",
    "                loss[i] += loss_fn(pred, y)\n",
    "        \n",
    "        loss = loss / num_batches\n",
    "    return loss\n",
    "\n",
    "def pre_transform(g, hops):\n",
    "            return create_subgraphs2(g, hops)\n",
    "    \n",
    "hops = {\n",
    "    \"Triangle\": 1,\n",
    "    \"2-Path\": 2,\n",
    "    \"4-Clique\": 1, \n",
    "    \"Chordal cycle\": 2,\n",
    "    \"Tailed triangle\": 2,\n",
    "    \"3-Star\": 2,\n",
    "    \"4-Cycle\": 2,\n",
    "    \"3-Path\": 3,\n",
    "    \"3-Star not ind.\": 2,\n",
    "}\n",
    "\n",
    "models_folder = results['config.model_folder'][1]\n",
    "model = results['config.model'][1]\n",
    "n_seeds = len(results['config.seeds'][1])\n",
    "test_set = results['config.test_dataset'][1]\n",
    "test = pd.DataFrame(columns=[\"Best_model\", \"L1 avg\", \"L1 std avg\", \"L1 count avg\",\"MSE var avg\", \"L1\", \"L1 std\", \"L1 count\", \"MSE var\"], index=substrucutres)\n",
    "\n",
    "gnns = {}\n",
    "for subgraph, line in tqdm(best_l1.iterrows()):\n",
    "    dict_models = results.loc[line['Best_model'], 'result.model_paths']\n",
    "    params_models = results.loc[line['Best_model'], 'result.h_param_paths']\n",
    "    if arch in ['GIN', 'PPGN']:\n",
    "        test_dataset = GraphDataset(test_set, subgraph, 1)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "        std = torch.std(test_dataset.labels)\n",
    "        var = torch.var(test_dataset.labels)\n",
    "    elif arch == 'I2GNN':\n",
    "        test_dataset = I2GNNDataset(root=os.path.dirname(test_set),dataset=os.path.basename(test_set),  subgraph_type=subgraph, pre_transform=pre_transform, hops=hops[subgraph])\n",
    "        test_loader = I2GNNDataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "        std = torch.std(test_dataset.data.y)\n",
    "        var = torch.var(test_dataset.data.y)\n",
    "    l1 = torch.nn.L1Loss()\n",
    "    l1_std = L1LossStd(std)\n",
    "    l1_count = L1LossCount()\n",
    "    mse = torch.nn.MSELoss()\n",
    "    \n",
    "    start = time.time()\n",
    "    gnns = []\n",
    "    for dict_model, params_model in zip(dict_models, params_models):\n",
    "        with open(params_model, 'r') as f:\n",
    "            h_params = json.load(f)\n",
    "        if arch == \"GIN\":\n",
    "            gnn = GIN(**h_params).to(device)\n",
    "        if arch == \"PPGN\":\n",
    "            gnn = PPGN(**h_params).to(device)\n",
    "        elif arch == 'I2GNN':\n",
    "            gnn = I2GNN(**h_params).to(device)\n",
    "        gnn.load_state_dict(torch.load(dict_model, map_location=torch.device(device)))\n",
    "        gnns.append(gnn)\n",
    "    # evaluate\n",
    "    l = [l1, l1_std, l1_count, mse]\n",
    "    l1_err = []\n",
    "    l1_std_err = []\n",
    "    l1_count_err = []\n",
    "    mse_err = []\n",
    "    for gnn in gnns:\n",
    "        err = evaluate_epoch(test_loader, gnn, l, device)\n",
    "        l1_err.append(err[0].item())\n",
    "        l1_std_err.append(err[1].item())\n",
    "        l1_count_err.append(err[2].item())\n",
    "        mse_err.append(err[3].item())\n",
    "    test.loc[subgraph] = [line[\"Best_model\"], mean(l1_err), mean(l1_std_err), mean(l1_count_err), median(mse_err), l1_err,l1_std_err, l1_count_err, mse_err]\n",
    "    print(f'{subgraph}: {mean(l1_err)}, time: {time.time() - start}')\n",
    "display(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we store the best mdels in a separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if exp != 'dataset_2':\n",
    "\n",
    "    destination_path = f\"/nfs/students/campi/best_models/{arch}_{exp}\"\n",
    "    os.makedirs(destination_path, exist_ok = True)\n",
    "\n",
    "    for subgraph, line in best_l1.iterrows():\n",
    "        original_models_path = results.loc[line['Best_model'], 'result.model_paths']\n",
    "        original_h_params_path = results.loc[line['Best_model'], 'result.h_param_paths']\n",
    "        for path in original_models_path:\n",
    "            file_parts = os.path.basename(path).split('_')\n",
    "            new_file = f\"{file_parts[0]}_{file_parts[1]}_{file_parts[-1]}\"\n",
    "            shutil.copyfile(path, os.path.join(destination_path, new_file))\n",
    "        for path in original_h_params_path:\n",
    "            file_parts = os.path.basename(path).split('_')\n",
    "            new_file = f\"{file_parts[0]}_{file_parts[1]}_{file_parts[-1]}\"\n",
    "            shutil.copyfile(path, os.path.join(destination_path, new_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the correctly classified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gnn_input(graph: nx.Graph, device)->torch_geometric.data.Data:\n",
    "    \"\"\"Creates from a networkx graph a Data instance, which is the input a a pytorch geometric model.\"\"\"\n",
    "    num_edges = graph.number_of_edges()\n",
    "    x = torch.ones(graph.number_of_nodes(), 1) # no improovement by using more channels in the first layer\n",
    "    edge_index = torch.empty(2, 2*num_edges, dtype=torch.long)\n",
    "    for i, edge in enumerate(graph.edges()):\n",
    "        edge_index[0,i] = edge[0]\n",
    "        edge_index[1,i] = edge[1]\n",
    "        edge_index[0, i+num_edges] = edge[1]\n",
    "        edge_index[1, i+num_edges] = edge[0]\n",
    "    return torch_geometric.data.Data(x=x, edge_index=edge_index).to(device)\n",
    "\n",
    "def pre_transform(g, hops):\n",
    "            return create_subgraphs2(g, hops)\n",
    "\n",
    "hops = {\n",
    "    \"Triangle\": 1,\n",
    "    \"2-Path\": 2,\n",
    "    \"4-Clique\": 1, \n",
    "    \"Chordal cycle\": 2,\n",
    "    \"Tailed triangle\": 2,\n",
    "    \"3-Star\": 2,\n",
    "    \"4-Cycle\": 2,\n",
    "    \"3-Path\": 3,\n",
    "    \"3-Star not ind.\": 2,\n",
    "}\n",
    "\n",
    "n_samples = 100\n",
    "test_set = results['config.test_dataset'][1]\n",
    "models_path = f\"/nfs/students/campi/best_models/{arch}_{exp}\"\n",
    "graphs, counts = dgl.load_graphs(results['config.test_dataset'].iloc[0])\n",
    "graphs = [nx.Graph(dgl.to_networkx(graph)) for graph in graphs]\n",
    "destination_path = os.path.dirname(results['config.test_dataset'].iloc[0])\n",
    "file_base = os.path.basename(results['config.test_dataset'].iloc[0]).split('.')[0]\n",
    "file_name = f'{file_base}_{arch}.json'\n",
    "l1 = torch.nn.L1Loss()\n",
    "\n",
    "adversarial_ids = {}\n",
    "for subgraph, line in tqdm(best_l1.iterrows()):\n",
    "    gnns = []\n",
    "    for i in range(5):\n",
    "        model_dict = f\"{models_path}/{arch}_{subgraph}_{i}.pth\"\n",
    "        model_params = f\"{models_path}/{arch}_{subgraph}_{i}.json\"\n",
    "        with open(model_params, 'r') as fp:\n",
    "            h_params = json.load(fp)\n",
    "        if arch == 'GIN':\n",
    "            gnns.append(GIN(**h_params).to(device))\n",
    "        elif arch == 'PPGN':\n",
    "            gnns.append(PPGN(**h_params).to(device))\n",
    "        elif arch == 'I2GNN':\n",
    "            gnns.append(I2GNN(**h_params).to(device))\n",
    "        else:\n",
    "            raise ValueError(\"The architecture is not supported!\")\n",
    "        gnns[-1].load_state_dict(torch.load(model_dict, map_location=torch.device(device)))\n",
    "        gnns[-1].eval()\n",
    "    correctly_pred_ids = []\n",
    "    if arch in ['GIN', 'PPGN']:\n",
    "        for i, (graph, count) in enumerate(zip(graphs, counts[subgraph])):\n",
    "            corr_pred = True\n",
    "            for gnn in gnns:\n",
    "                err = l1(gnn(generate_gnn_input(graph, device)).flatten(), count)\n",
    "                if  err >= 0.5:\n",
    "                    corr_pred = False\n",
    "                    break\n",
    "            if corr_pred == True:\n",
    "                correctly_pred_ids.append(i)\n",
    "            if len(correctly_pred_ids) == n_samples:\n",
    "                print(f'{subgraph} has enough at {i}')\n",
    "                break\n",
    "        adversarial_ids[subgraph] = correctly_pred_ids\n",
    "        print(f'{subgraph}: {len(correctly_pred_ids)}')\n",
    "    if arch == 'I2GNN':\n",
    "        test_dataset = I2GNNDataset(root=os.path.dirname(test_set),dataset=os.path.basename(test_set),  subgraph_type=subgraph, pre_transform=pre_transform, hops=hops[subgraph])\n",
    "        test_loader = I2GNNDataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data.to(device)\n",
    "            corr_pred = True\n",
    "            for gnn in gnns:\n",
    "                err = l1(gnn(data), data.y)\n",
    "                if  err >= 0.5:\n",
    "                    corr_pred = False\n",
    "                    break\n",
    "            if corr_pred == True:\n",
    "                correctly_pred_ids.append(i)\n",
    "            if len(correctly_pred_ids) == n_samples:\n",
    "                print(f'{subgraph} has enough at {i}')\n",
    "                break\n",
    "        adversarial_ids[subgraph] = correctly_pred_ids\n",
    "        print(f'{subgraph}: {len(correctly_pred_ids)}')\n",
    "    \n",
    "# write the json file\n",
    "with open(os.path.join(destination_path, file_name), 'w') as f:\n",
    "    json.dump(adversarial_ids, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "14a2f470a07c2e566eb95c5ff40185cf14648f574a8be0a5f752ff57828c9fe4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
